{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.stats import mode\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from math import log10, floor\n",
    "from metric_learn import LMNN\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- Functions ---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Generate Subsets -- #\n",
    "def gen_subset (d, train):\n",
    "    #subs = [];\n",
    "    subs = np.zeros(shape = [5, np.int(d/100 * train.shape[0]), train.shape[1]])\n",
    "    subs[0,:] = ( train[np.random.choice(train.shape[0], np.int(d/100 * train.shape[0]), replace = False)] );\n",
    "    subs[1,:] = ( train[np.random.choice(train.shape[0], np.int(d/100 * train.shape[0]), replace = False)] );\n",
    "    subs[2,:] = ( train[np.random.choice(train.shape[0], np.int(d/100 * train.shape[0]), replace = False)] );\n",
    "    subs[3,:] = ( train[np.random.choice(train.shape[0], np.int(d/100 * train.shape[0]), replace = False)] );\n",
    "    subs[4,:] = ( train[np.random.choice(train.shape[0], np.int(d/100 * train.shape[0]), replace = False)] );\n",
    "    return subs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- LMNN try catch block ---- #\n",
    "def lmnn_fit_fn(data, k_inp):\n",
    "    lmnn = lmnn_arr[[np.where(k == 5)][0][0][0]]\n",
    "    \n",
    "    try:\n",
    "        #lmnn = LMNN(k = k_inp, learn_rate=1e-6)\n",
    "        lmnn.fit(data[:,1:], np.reshape(data[:,0], (1,-1)),  verbose = False)\n",
    "        data_tx = lmnn.transform(data[:,1:])\n",
    "    except AssertionError:\n",
    "        data_tx = data[:,1:]\n",
    "    except IndexError:\n",
    "        data_tx = lmnn.transform(data[:,1:]);\n",
    "\n",
    "    return data_tx;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- cross validation -- #\n",
    "def CV (train, test, k_inp):\n",
    "    #LMNN\n",
    "    # Fit Train data to lmnn\n",
    "    train_tx = lmnn_fit_fn(train, k_inp)       \n",
    "    \n",
    "    # Fit test data to lmnn\n",
    "    test_tx = lmnn_fit_fn(test, k_inp)\n",
    "            \n",
    "    y_train = train[:,0]\n",
    "    y_test = test[:,0]\n",
    "           \n",
    "    acc = knn_fn(train_tx, test_tx, y_train, y_test, k_inp)\n",
    "    \n",
    "    return acc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----- KNN ----- #\n",
    "def knn_fn (train_mat, test_mat, y_train, y_test, k_inp):\n",
    "    \n",
    "    knn_fn.counter += 1;\n",
    "\n",
    "    euc_dist = np.zeros(test_mat.shape[0])\n",
    "    y_new = np.zeros(test_mat.shape[0])    \n",
    "    for i in range (test_mat.shape[0]):\n",
    "        euc_dist = euclidean_distances(train_mat, np.reshape(test_mat[i], (1,-1)))        \n",
    "        #np.reshape(test_mat[i], (1,-1)))        \n",
    "        if euc_dist.shape[0] > k_inp :            \n",
    "            dist_sort = np.argpartition(euc_dist.T, k_inp - 1)            \n",
    "            y_new[i] = mode(y_train[dist_sort[0,0:k_inp]])[0] #K NN            \n",
    "        else:\n",
    "            y_new[i] = mode(y_train)[0]            \n",
    "            #dist_sort = np.arange(euc_dist.shape[0]);\n",
    "            #np.argpartition(euc_dist.T, euc_dist.shape[0] - 1) #.T  transpose\n",
    "#    print(np.shape(y_new))\n",
    "#    print(np.shape(y_test))\n",
    "    accuracy_table = accuracy_score(y_test, y_new)      \n",
    "    return accuracy_table\n",
    "knn_fn.counter = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------ Main Code ------ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ...  2016-04-03 01:38:09\n",
      "done 2016-04-03 01:38:55\n"
     ]
    }
   ],
   "source": [
    "#Select input dataset input_dataset = 1 for wine, input_dataset = 2 for MNIST, input_dataset = 3 for office dataset\n",
    "input_dataset = 3\n",
    "\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Loading Data ... ', st)\n",
    "\n",
    "## import inputs wine dataset\n",
    "fwine = open('wine.data', 'r')\n",
    "wineraw = np.loadtxt(\"wine.data\", comments=\"#\", delimiter=\",\", unpack=False) #178x14\n",
    "wineclass = wineraw[:,1]\n",
    "winedata = wineraw[:,1:len(wineraw[2,:])]\n",
    "\n",
    "## import MNIST Dataset\n",
    "if (input_dataset ==2):\n",
    "    ftrain = open('mnisttrain.csv', 'r')\n",
    "    ftest = open('mnisttest.csv','r')\n",
    "    mnist_trainraw = np.loadtxt(\"mnisttrain.csv\", comments=\"#\", delimiter=\",\", unpack=False) #785xsamp\n",
    "    mnist_testraw = np.loadtxt(\"mnisttest.csv\", comments=\"#\", delimiter=\",\", unpack=False) #785xsamp\n",
    "    #mnist_raw = np.append(mnist_trainraw,mnist_testraw,axis = 1)\n",
    "    #mnist_raw = np.roll(np.transpose(mnist_raw),1,axis=1)\n",
    "    \n",
    "if (input_dataset == 3):\n",
    "    ftrain = open('officetrain.csv', 'r')\n",
    "    ftest = open('officetest.csv','r')\n",
    "    off_trainraw = np.loadtxt(\"officetrain.csv\", comments=\"#\", delimiter=\",\", unpack=False) #785xsamp\n",
    "    off_testraw = np.loadtxt(\"officetest.csv\", comments=\"#\", delimiter=\",\", unpack=False) #785xsamp\n",
    "    #off_raw = np.append(mnist_trainraw,mnist_testraw,axis = 1)\n",
    "    #off_raw = np.roll(np.transpose(mnist_raw),1,axis=1)\n",
    "    \n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('done', st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---- Splitting Data to test train ---- #\n",
    "if (input_dataset == 1):\n",
    "    train, test = train_test_split(wineraw, train_size = 0.80)\n",
    "elif (input_dataset == 2):\n",
    "    train = np.roll(np.transpose(mnist_trainraw),1,axis=1)\n",
    "    test = np.roll(np.transpose(mnist_testraw),1,axis=1)              \n",
    "elif (input_dataset == 3):\n",
    "    train = np.roll(off_trainraw,1,axis=1)\n",
    "    test = np.roll(off_testraw,1,axis=1)\n",
    "    train = train[:,0:train.shape[1]-2]\n",
    "    test = test[:,0:test.shape[1]-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gartiya\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#if (input_dataset == 1):\n",
    "# ----- LDA ----- #\n",
    "lda_model = LDA()\n",
    "temp_data = lda_model.fit_transform(train[:,1:], train[:,0])\n",
    "train = np.append(np.reshape(train[:,0], (-1,1)), temp_data, axis = 1 )\n",
    "\n",
    "temp_data = lda_model.transform(test[:,1:])\n",
    "test = np.append(np.reshape(test[:,0], (-1,1)), temp_data, axis = 1 )\n",
    "\n",
    "#elif (input_dataset == 2):\n",
    "#    # ----- Mnist Dataset ----- #\n",
    "#    tsne_model = TSNE();\n",
    "#    temp_data = tsne_model.fit_transform(train[:,1:])\n",
    "#    train = np.append(np.reshape(train[:,0], (-1,1)), temp_data, axis = 1 )\n",
    "    \n",
    "#    tsne_model = TSNE()\n",
    "#    temp_data = tsne_model.fit_transform(test[:,1:])\n",
    "#    test = np.append(np.reshape(test[:,0], (-1,1)), temp_data, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Data Loaded  2016-04-03 01:38:58\n"
     ]
    }
   ],
   "source": [
    "# ---- Randomly select a subset of d = (20; 50; 80; 100) ----- #\n",
    "subsets20 = np.zeros(shape = [5, np.int(20/100 * train.shape[0]), train.shape[1]])\n",
    "subsets50 = np.zeros(shape = [5, np.int(50/100 * train.shape[0]), train.shape[1]])\n",
    "subsets80 = np.zeros(shape = [5, np.int(80/100 * train.shape[0]), train.shape[1]])\n",
    "\n",
    "subsets20 = gen_subset(20,train)\n",
    "subsets50 = gen_subset(50,train)\n",
    "subsets80 = gen_subset(80,train)\n",
    "\n",
    "print('done')\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Data Loaded ', st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = np.array([5,7,10])\n",
    "d_val = 3\n",
    "lmnn_arr = []\n",
    "subset_val = 5\n",
    "\n",
    "if (input_dataset == 1):\n",
    "    fold_val = 3 # includes leave one out for wine dataset\n",
    "else:\n",
    "    fold_val = 2        \n",
    "\n",
    "for k_it in range(0,k.shape[0],1):\n",
    "    lmnn_arr.append( LMNN(k = k[k_it], learn_rate=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Accuracy matrix  2016-04-03 01:38:59\n",
      "d  0\n",
      "subset  0\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  1\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  2\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  3\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  4\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "d  1\n",
      "subset  0\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  1\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  2\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  3\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  4\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "d  2\n",
      "subset  0\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  1\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  2\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  3\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset  4\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "subset 100%\n",
      "2 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "5 Fold\n",
      "k  0\n",
      "k  1\n",
      "k  2\n",
      "done\n",
      "Accuracy matrix generated  2016-04-03 14:30:35\n"
     ]
    }
   ],
   "source": [
    "# ---- Finding K fold train and test indices ----- #\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Computing Accuracy matrix ',st)\n",
    "\n",
    "        \n",
    "accuracy_mat = np.zeros(shape = [d_val,subset_val,fold_val,k.shape[0]]) #d,subset,fold, k. #2fold = 0, #5fold = 1 #LOO = 2.\n",
    "\n",
    "for d_it in range(0,3,1):\n",
    "    print('d ',d_it)\n",
    "    if (d_it == 0):\n",
    "        subsets = subsets20\n",
    "    elif (d_it == 1):\n",
    "        subsets = subsets50        \n",
    "    elif (d_it == 2):\n",
    "        subsets = subsets80   \n",
    "         \n",
    "    for sub_it in range(0,5,1): \n",
    "        print('subset ',sub_it)\n",
    "        \n",
    "        #@ 2 fold Cross Validation\n",
    "        kf = KFold(subsets[sub_it].shape[0], n_folds=2)\n",
    "        print('2 Fold')\n",
    "        for k_it in range(0,k.shape[0],1):           \n",
    "            print('k ',k_it)\n",
    "            acc_sum= 0;            \n",
    "            for train_index, test_index in kf:\n",
    "                acc = CV(subsets[sub_it][train_index, :], subsets[sub_it][test_index,:], k[k_it])\n",
    "                acc_sum = acc_sum + acc;\n",
    "            accuracy_mat[d_it,sub_it,0,k_it] = acc_sum/2;                        \n",
    "        \n",
    "        ## 5 fold Cross Validation\n",
    "        kf = KFold(subsets[sub_it].shape[0], n_folds=5)\n",
    "        print('5 Fold')\n",
    "        for k_it in range(0,k.shape[0],1):\n",
    "            print('k ',k_it)\n",
    "            acc_sum= 0;\n",
    "            for train_index, test_index in kf:\n",
    "                acc = CV(subsets[sub_it][train_index, :], subsets[sub_it][test_index,:], k[k_it])\n",
    "                acc_sum = acc_sum + acc;            \n",
    "            accuracy_mat[d_it,sub_it,1,k_it] = acc_sum/5;\n",
    "\n",
    "        if(input_dataset == 1):\n",
    "            #Leave one out fold Cross Validation\n",
    "            print('Leave one out')\n",
    "            kf = KFold(subsets[sub_it].shape[0], n_folds=subsets[sub_it].shape[0])\n",
    "            for k_it in range(0,k.shape[0],1): \n",
    "                print('k ',k_it)\n",
    "                acc_sum= 0;\n",
    "                for train_index, test_index in kf:\n",
    "                    acc = CV(subsets[sub_it][train_index, :], subsets[sub_it][test_index,:], k[k_it])\n",
    "                    acc_sum = acc_sum + acc;            \n",
    "                accuracy_mat[d_it,sub_it,2,k_it] =  acc_sum/subsets[sub_it].shape[0];\n",
    "\n",
    "print('subset 100%',)            \n",
    "# for d = 100%\n",
    "accuracy_mat_100d = np.zeros(shape = [fold_val,k.shape[0]]) #d,subset,fold, k. #2fold = 0, #5fold = 1 #LOO = 2.\n",
    "#@ 2 fold Cross Validation\n",
    "kf = KFold(subsets[sub_it].shape[0], n_folds=2)\n",
    "print('2 Fold')\n",
    "for k_it in range(0,k.shape[0],1): \n",
    "    print('k ',k_it)\n",
    "    acc_sum= 0;            \n",
    "    for train_index, test_index in kf:\n",
    "        acc = CV(subsets[sub_it][train_index, :], subsets[sub_it][test_index,:], k[k_it])\n",
    "        acc_sum = acc_sum + acc;\n",
    "    accuracy_mat_100d[0,k_it] = acc_sum/2;                        \n",
    "\n",
    "## 5 fold Cross Validation\n",
    "kf = KFold(subsets[sub_it].shape[0], n_folds=5)\n",
    "print('5 Fold')\n",
    "for k_it in range(0,k.shape[0],1): \n",
    "    print('k ',k_it)\n",
    "    acc_sum= 0;\n",
    "    for train_index, test_index in kf:\n",
    "        acc = CV(subsets[sub_it][train_index, :], subsets[sub_it][test_index,:], k[k_it])\n",
    "        acc_sum = acc_sum + acc;            \n",
    "    accuracy_mat_100d[1,k_it] = acc_sum/5;\n",
    "\n",
    "\n",
    "if (input_dataset == 1):\n",
    "    #Leave one out fold Cross Validation\n",
    "    kf = KFold(subsets[sub_it].shape[0], n_folds=subsets[sub_it].shape[0])\n",
    "    print('Leave one out')\n",
    "    for k_it in range(0,k.shape[0],1): \n",
    "        print('k ',k_it)\n",
    "        acc_sum= 0;\n",
    "        for train_index, test_index in kf:\n",
    "            acc = CV(subsets[sub_it][train_index, :], subsets[sub_it][test_index,:], k[k_it])\n",
    "            acc_sum = acc_sum + acc;            \n",
    "        accuracy_mat_100d[2,k_it] =  acc_sum/subsets[sub_it].shape[0];\n",
    "\n",
    "\n",
    "print('done')\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Accuracy matrix generated ',st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K =  5\n",
      "Final Accuracy Score =  0.534707724426\n",
      "Execution end time  2016-04-03 14:37:57\n"
     ]
    }
   ],
   "source": [
    "# ---- Finding best K ---- #\n",
    "acc_sum_k = np.zeros(shape = k.shape[0])\n",
    "acc_sum_100d = np.zeros(shape = k.shape[0])\n",
    "for k_int in range(0,k.shape[0],1):\n",
    "    acc_sum_k[k_int] = np.sum (accuracy_mat[:,:,:,k_int])\n",
    "    acc_sum_100d[k_int] = np.sum(accuracy_mat_100d[:,k_int])\n",
    "\n",
    "den = (d_val * subset_val * fold_val) + (fold_val)\n",
    "acc_means_k = np.zeros(shape = k.shape[0])\n",
    "acc_mean_k = (np.add(acc_sum_k, acc_sum_100d))/den\n",
    "    \n",
    "k_best = k[np.argmax(acc_means_k)]\n",
    "\n",
    "# ----- Applying the best K to test data and finding final accuracy ----- #\n",
    "\n",
    "# Fit train data to lmnn\n",
    "train_tx = lmnn_fit_fn(train, k_best)\n",
    "\n",
    "# Fit test data to lmnn\n",
    "test_tx = lmnn_fit_fn(test, k_best)\n",
    "\n",
    "acc_best_k = knn_fn(train_tx, test_tx, train[:,0], test[:,0], k_best)\n",
    "print('Best K = ',k_best)\n",
    "print('Final Accuracy Score = ',acc_best_k)\n",
    "\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Execution end time ',st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K =  5\n",
      "Final Accuracy Score =  0.534707724426\n",
      "Execution end time  2016-04-03 14:45:11\n",
      "Best K =  7\n",
      "Final Accuracy Score =  0.544798190675\n",
      "Execution end time  2016-04-03 14:52:20\n",
      "Best K =  10\n",
      "Final Accuracy Score =  0.552800974252\n",
      "Execution end time  2016-04-03 14:59:42\n"
     ]
    }
   ],
   "source": [
    "for k_best in k:\n",
    "    # Fit train data to lmnn\n",
    "    train_txa = lmnn_fit_fn(train, k_best)\n",
    "\n",
    "    # Fit test data to lmnn\n",
    "    test_txa = lmnn_fit_fn(test, k_best)\n",
    "\n",
    "    acc_best_k = knn_fn(train_txa, test_txa, train[:,0], test[:,0], k_best)\n",
    "    print('Best K = ',k_best)\n",
    "    print('Final Test Accuracy Score = ',acc_best_k)\n",
    "    print('Test Error percentage for best k = ', (1-acc_best_k)*100,'%')\n",
    "    \n",
    "\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print('Execution end time ',st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy 0.651362506107\n",
      "Cross Validation Error =  34.8637493893 %\n"
     ]
    }
   ],
   "source": [
    "#Cross_Validation accuracy\n",
    "cv_acc = (np.sum(accuracy_mat[:,:,:,np.where(k==k_best)]) + np.sum(accuracy_mat_100d[:,np.where(k==k_best)])) /(d_val* subset_val * fold_val + fold_val) \n",
    "print('CV accuracy', cv_acc)\n",
    "print('Cross Validation Error = ', (1-cv_acc)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64453023  0.66284382]\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "# Which F worked best\n",
    "acc_sum_f = np.zeros(shape = fold_val)\n",
    "acc_sum_100d_f = np.zeros(shape = fold_val)\n",
    "for f_int in range(0,fold_val,1):\n",
    "    acc_sum_f[f_int] = np.sum (accuracy_mat[:,:,f_int,:])\n",
    "    acc_sum_100d_f[f_int] = np.sum(accuracy_mat_100d[f_int,:])\n",
    "\n",
    "den = (d_val * subset_val * k.shape[0]) + (k.shape[0])\n",
    "acc_means_f = np.zeros(shape = fold_val)\n",
    "acc_mean_f = (np.add(acc_sum_f, acc_sum_100d_f))/den\n",
    "\n",
    "print('Accuracy with respect to 2 Fold, 5 fold', acc_mean_f )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62485974  0.6552153   0.67665533]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#Statbility over subset of same size\n",
    "\n",
    "acc_sum_sub = np.zeros(shape = [d_val, subset_val])\n",
    "for d_int in range(0,d_val,1):\n",
    "    for sub_int in range(0,subset_val,1):\n",
    "        acc_sum_sub[d_int,sub_int] = np.sum(accuracy_mat[d_int,sub_int,:,:])  \n",
    "        \n",
    "\n",
    "den = (fold_val * k.shape[0])\n",
    "acc_sum_sub = acc_sum_sub/den\n",
    "\n",
    "acc_var_sub = np.zeros(shape = 3)\n",
    "acc_var_sub[0] = np.var(acc_sum_sub[0,:])\n",
    "acc_var_sub[1] = np.var(acc_sum_sub[1,:])\n",
    "acc_var_sub[2] = np.var(acc_sum_sub[2,:])        \n",
    "\n",
    "print('Stability of accuracy for each subset size:')\n",
    "print('Variance in accuracy of between the subsets of same size is ', acc_var_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
